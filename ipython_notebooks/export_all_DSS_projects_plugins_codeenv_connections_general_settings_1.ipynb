{
  "metadata": {
    "createdOn": 1746840382892,
    "creator": "tim.honker@dataiku.com",
    "customFields": {},
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "modifiedBy": "admin",
    "tags": [],
    "dkuGit": {
      "lastInteraction": 1756906584241,
      "gitReference": {
        "remote": "git@github.com:THE-MOLECULAR-MAN/dss_private.git",
        "checkout": "main",
        "remotePath": "admin/export_all_DSS_projects_plugins_codeenv_connections_general_settings.ipynb",
        "remoteLogin": "",
        "lastHash": "bff3dd4953aa25023588eefba71b9b9f6a8dfc45",
        "lastTimestamp": 1755800954000,
        "isDirty": false
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import json\n",
        "import os\n",
        "# import datetime\n",
        "from datetime import datetime\n",
        "import copy\n",
        "\n",
        "import dataiku\n",
        "from dataikuapi import DSSClient"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "EXPORT_FOLDER_ID \u003d \"5fuFDP0G\"\n",
        "\n",
        "# https://developer.dataiku.com/latest/api-reference/python/projects.html#dataikuapi.dss.project.DSSProject.export_to_file\n",
        "EXPORT_OPTIONS \u003d {\n",
        "    \u0027exportUploads\u0027: True,\n",
        "    \u0027exportGitRepository\u0027: True,\n",
        "    \u0027exportUploads\u0027: True,\n",
        "    #\u0027exportManagedFS\u0027: True,\n",
        "    \u0027exportAnalysisModels\u0027: True,\n",
        "    \u0027exportSavedModels\u0027: True,\n",
        "    \u0027exportModelEvaluationStores\u0027: True,\n",
        "    \u0027exportAllInputDatasets\u0027: True, # this is okay, does not include folders that have files like screenshots\n",
        "    #\u0027exportAllInputManagedFolders\u0027: True,\n",
        "    \u0027exportInsightsData\u0027: True,\n",
        "    \u0027exportPromptStudioHistories\u0027: True,\n",
        "     }"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "export_timestamp \u003d datetime.now().strftime(\u0027%Y%m%d_%H%M%S\u0027)\n",
        "\n",
        "client \u003d dataiku.api_client()\n",
        "export_folder_handle \u003d dataiku.Folder(EXPORT_FOLDER_ID)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "SENSITIVE_FIELDS \u003d [\n",
        "    \"password\", \"passwords\", \"apiKey\", \"apiKeys\", \"token\", \"tokens\",\n",
        "    \"secret\", \"secrets\", \"privateKey\", \"privateKeys\", \"key\", \"appSecret\",\n",
        "    \"appSecretContent\", \"credential\", \"credentials\", \"accessKey\",\n",
        "    \"secretKey\", \"authToken\", \"connectionString\", \"pwd\"\n",
        "]\n",
        "\n",
        "def sanitize_dict(obj):\n",
        "    \"\"\" Recursively scan a dictionary and remove/sanitize sensitive information \"\"\"\n",
        "    if not isinstance(obj, dict):\n",
        "        return obj\n",
        "    \n",
        "    result \u003d copy.deepcopy(obj)\n",
        "    \n",
        "    for key, value in list(result.items()):\n",
        "        # Check if the key contains any sensitive field names\n",
        "        if any(sensitive in key.lower() for sensitive in SENSITIVE_FIELDS):\n",
        "            if isinstance(value, str) and value:  # Only replace non-empty strings\n",
        "                result[key] \u003d \"[REDACTED]\"\n",
        "            elif isinstance(value, dict):  # If it\u0027s a dictionary, still process it\n",
        "                result[key] \u003d sanitize_dict(value)\n",
        "        # Recursively process nested dictionaries\n",
        "        elif isinstance(value, dict):\n",
        "            result[key] \u003d sanitize_dict(value)\n",
        "        # Process items in lists\n",
        "        elif isinstance(value, list):\n",
        "            result[key] \u003d [sanitize_dict(item) if isinstance(item, dict) else item for item in value]\n",
        "            \n",
        "    return result"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "project_keys \u003d client.list_project_keys()\n",
        "\n",
        "for project_key in project_keys:\n",
        "    project \u003d client.get_project(project_key)    \n",
        "    \n",
        "    # Get the summary of the project, which includes the last modified timestamp\n",
        "    project_summary \u003d project.get_summary()\n",
        "    #print(project_summary)\n",
        "\n",
        "    # The last modified timestamp can be extracted as follows\n",
        "    # The timestamp is typically in milliseconds since epoch (standard Unix time)\n",
        "    last_modified_timestamp \u003d project_summary.get(\u0027versionTag\u0027, None).get(\u0027lastModifiedOn\u0027, None)\n",
        "    # print(last_modified_timestamp)\n",
        "\n",
        "    # Convert the timestamp to a human-readable format, if necessary\n",
        "    if last_modified_timestamp:\n",
        "        last_modified_date \u003d datetime.fromtimestamp(last_modified_timestamp / 1000)\n",
        "        formatted_date \u003d last_modified_date.strftime(\u0027%Y-%m-%d-%H-%M-%S\u0027)\n",
        "        # print(f\"Project \u0027{project_key}\u0027 was last modified on: {formatted_date}\")\n",
        "    else:\n",
        "        formatted_date\u003d\u0027unknown_date\u0027\n",
        "    \n",
        "    export_file_path \u003d \u0027/tmp/{}.zip\u0027.format(project_key)\n",
        "    \n",
        "    # Export the project to a local file\n",
        "    print(f\"Starting export for {project_key} ...\")\n",
        "    project.export_to_file(export_file_path, options\u003dEXPORT_OPTIONS)\n",
        "    print(f\"Finished export for {project_key} ...\")\n",
        "    \n",
        "    # Upload the exported file to the managed folder\n",
        "    with open(export_file_path, \u0027rb\u0027) as f:\n",
        "        print(f\"Starting copy to folder: {project_key} ...\")\n",
        "        upload_filename\u003df\u0027PROJECT__{project_key}__{formatted_date}.zip\u0027\n",
        "        export_folder_handle.upload_stream(upload_filename, f)\n",
        "        print(f\"Finished copying to folder: {project_key} ...\")\n",
        "        os.remove(export_file_path)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plugins \u003d client.list_plugins()\n",
        "\n",
        "# Filter the plugins to include only those installed from the store\n",
        "store_plugins \u003d [plugin[\u0027id\u0027] for plugin in plugins] # if plugin.get(\u0027isInstalledFromStore\u0027, False)]\n",
        "\n",
        "# Path for the output text file\n",
        "plugins_output_file_path \u003d \u0027/tmp/store_plugins.txt\u0027\n",
        "\n",
        "# Write the plugin IDs to a text file\n",
        "with open(plugins_output_file_path, \u0027w\u0027) as output_file:\n",
        "    for plugin_id in store_plugins:\n",
        "        output_file.write(plugin_id + \u0027\\n\u0027)\n",
        "\n",
        "# Upload the text file to the managed folder\n",
        "with open(plugins_output_file_path, \u0027rb\u0027) as f:\n",
        "    export_folder_handle.upload_stream(f\u0027list_plugins_{export_timestamp}.txt\u0027, f)\n",
        "\n",
        "# Cleaning up the temporary file\n",
        "os.remove(plugins_output_file_path)\n",
        "\n",
        "print(\"Plugin IDs exported to the managed folder.\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "try:\n",
        "    # Retrieve list of all connections\n",
        "    connections \u003d client.list_connections()\n",
        "    \n",
        "    # Prepare detailed connection information for export\n",
        "    connections_details \u003d []\n",
        "    for conn in connections:\n",
        "        # Obtain connection details\n",
        "        conn_detail \u003d client.get_connection(conn).get_definition()\n",
        "        \n",
        "        # Add connection details to list\n",
        "        #connections_details.append(conn_detail)\n",
        "        sanitized_conn \u003d sanitize_dict(conn_detail)\n",
        "        \n",
        "        # Add sanitized connection details to list\n",
        "        connections_details.append(sanitized_conn)\n",
        "        \n",
        "    # Define output file name and path\n",
        "    connections_output_filepath \u003d \u0027/tmp/connections.txt\u0027\n",
        "    \n",
        "    # Write connection details to JSON file\n",
        "    with open(connections_output_filepath, \u0027w\u0027) as file:\n",
        "        json.dump(connections_details, file, indent\u003d4)\n",
        "\n",
        "\n",
        "    # Upload the text file to the managed folder\n",
        "    with open(connections_output_filepath, \u0027rb\u0027) as f:\n",
        "        export_folder_handle.upload_stream(f\"list_connections_{export_timestamp}.json\", f)\n",
        "        os.remove(connections_output_filepath)\n",
        "        \n",
        "    print(f\"Connection details successfully exported to managed folder.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Code Environment names\n",
        "code_env_name_list \u003d sorted([env[\u0027envName\u0027] for env in client.list_code_envs()])\n",
        "\n",
        "with open(\u0027code_env_names.txt\u0027, \u0027w\u0027) as f:\n",
        "    f.write(\u0027\\n\u0027.join(code_env_name_list))\n",
        "    \n",
        "# Upload the text file to the managed folder\n",
        "with open(\u0027code_env_names.txt\u0027, \u0027rb\u0027) as f:\n",
        "    export_folder_handle.upload_stream(f\"list_codeenvs_{export_timestamp}.txt\", f)\n",
        "    \n",
        "    os.remove(\u0027code_env_names.txt\u0027)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "def export_code_environments():\n",
        "    \"\"\" Exports all code environment settings to a JSON file. \"\"\"\n",
        "    try:\n",
        "        # Get all code environments\n",
        "        code_envs_list \u003d client.list_code_envs()\n",
        "        \n",
        "        # Prepare a dictionary to store all environment details\n",
        "        code_envs_details \u003d {\n",
        "            \"python\": [],\n",
        "#             \"r\": [],\n",
        "#             \"julia\": []\n",
        "        }\n",
        "        \n",
        "        # Process Python environments\n",
        "        for env in code_envs_list:\n",
        "            env_name \u003d env.get(\"envName\")\n",
        "            try:\n",
        "                # Get detailed definition of the code environment\n",
        "                env_details \u003d client.get_code_env(\"python\", env_name).get_definition()\n",
        "                code_envs_details[\"python\"].append(env_details)\n",
        "                # print(f\"Exported Python environment: {env_name}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error exporting Python environment {env_name}: {str(e)}\")\n",
        "        \n",
        "        # Process R environments\n",
        "#         for env in code_envs_list.get(\"r\", []):\n",
        "#             env_name \u003d env.get(\"envName\")\n",
        "#             try:\n",
        "#                 env_details \u003d client.get_code_env(\"r\", env_name).get_definition()\n",
        "#                 code_envs_details[\"r\"].append(env_details)\n",
        "#                 print(f\"Exported R environment: {env_name}\")\n",
        "#             except Exception as e:\n",
        "#                 print(f\"Error exporting R environment {env_name}: {str(e)}\")\n",
        "        \n",
        "#         # Process Julia environments\n",
        "#         for env in code_envs_list.get(\"julia\", []):\n",
        "#             env_name \u003d env.get(\"envName\")\n",
        "#             try:\n",
        "#                 env_details \u003d client.get_code_env(\"julia\", env_name).get_definition()\n",
        "#                 code_envs_details[\"julia\"].append(env_details)\n",
        "#                 print(f\"Exported Julia environment: {env_name}\")\n",
        "#             except Exception as e:\n",
        "#                 print(f\"Error exporting Julia environment {env_name}: {str(e)}\")\n",
        "        \n",
        "        # Define output file name and path with timestamp\n",
        "        output_filename \u003d f\"code_environments_export.json\"\n",
        "        \n",
        "        # Write code environment details to JSON file\n",
        "        with open(output_filename, \u0027w\u0027) as file:\n",
        "            json.dump(sanitize_dict(code_envs_details), file, indent\u003d4)\n",
        "            \n",
        "        with open(output_filename, \u0027rb\u0027) as f:\n",
        "            export_folder_handle.upload_stream(f\"list_codeenvs_{export_timestamp}.json\", f)\n",
        "            os.remove(output_filename)\n",
        "        \n",
        "        print(f\"\\nCode environment details successfully saved to {output_filename}\")\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during export: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "    \n",
        "export_code_environments()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "settings_raw \u003d client.get_general_settings().get_raw()\n",
        "settings_output_filename \u003d \u0027general_settings.json\u0027\n",
        "with open(settings_output_filename, \u0027w\u0027) as file:\n",
        "    json.dump(sanitize_dict(settings_raw), file, indent\u003d4)\n",
        "\n",
        "with open(settings_output_filename, \u0027rb\u0027) as f:\n",
        "    export_folder_handle.upload_stream(f\"general_settings_{export_timestamp}.json\", f)\n",
        "    os.remove(settings_output_filename)\n",
        "\n",
        "print(\u0027Finished exporting settings.\u0027)\n"
      ],
      "outputs": []
    }
  ]
}