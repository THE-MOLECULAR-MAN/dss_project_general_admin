{
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.21",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "demo",
    "versionNumber": 2,
    "dkuGit": {
      "lastInteraction": 1756906848876,
      "gitReference": {
        "remote": "git@github.com:THE-MOLECULAR-MAN/dss_private.git",
        "checkout": "main",
        "remotePath": "admin/clear_calculated_datasets.ipynb",
        "remoteLogin": "",
        "lastHash": "19311061565e9449682d8d5e9100de7bb01194db",
        "lastTimestamp": 1756906681000,
        "isDirty": false
      }
    },
    "creator": "tim.honker@dataiku.com",
    "tags": [],
    "customFields": {},
    "createdOn": 1743519915912
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clear all calculated datasets for full build\n\nClears datasets unless they are:\n* only an input and not an output\n* not used as an input, nor an output (isolated)\n* an input or output to a Text Extraction or knowledge bank recipe"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from dataiku import api_client"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Connect to the Dataiku instance\nclient \u003d api_client()\nproject \u003d client.get_default_project()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def extract_key_values(dict_list, key):\n    \"\"\"\n    Extracts the set of values associated with a given key from a list of dictionaries.\n\n    Parameters:\n        dict_list (list): List of dictionaries.\n        key (str): The key whose values you want to extract.\n\n    Returns:\n        set: A set of values corresponding to the given key.\n    \"\"\"\n    return {d[key] for d in dict_list if key in d}"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "all_datasets \u003d extract_key_values(project.list_datasets(), \"name\")\nall_datasets"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "all_recipes \u003d project.list_recipes()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "input_datasets \u003d set()\n\nkeys_to_extract \u003d [\u0027main\u0027, \u0027output_dataset\u0027, \u0027input_folder\u0027, \u0027knowledge_bank\u0027]\n\nfor recipe in all_recipes:\n    input_node \u003d recipe[\u0027inputs\u0027]\n    print(input_node)\n    for key in keys_to_extract:\n        if key in input_node:\n            for input2 in input_node[key][\u0027items\u0027]:\n                input_datasets.add(input2[\u0027ref\u0027])\n\ninput_datasets"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "output_datasets \u003d set()\n\nfor recipe in all_recipes:\n    output_node \u003d recipe[\u0027outputs\u0027]\n    print(output_node)\n    \n    for key in keys_to_extract:\n        if key in output_node:\n            for output2 in output_node[key][\"items\"]:\n                output_datasets.add(output2[\u0027ref\u0027])\n\n            \noutput_datasets"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "input_only_datasets \u003d input_datasets - output_datasets\ninput_only_datasets"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "non_input_datasets \u003d all_datasets - input_only_datasets\nnon_input_datasets"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "isolated_datasets \u003d all_datasets - input_datasets - output_datasets\nisolated_datasets"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "datasets_to_clear \u003d non_input_datasets - isolated_datasets\ndatasets_to_clear"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "datasets_to_leave_alone \u003d all_datasets - datasets_to_clear\ndatasets_to_leave_alone"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# # Clear each non-input dataset\n# for dataset_name in datasets_to_clear:\n#     if dataset_name in all_datasets:   # don\u0027t try to clear knowledge banks and stuff\n#         dataset \u003d project.get_dataset(dataset_name)\n#         dataset.clear()  # Clears all data in the dataset\n#         print(f\"Cleared dataset: {dataset_name}\")\n\n# print(\"Finished clearing non-input datasets.\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# There is not an API method to delete/clear/clean/empty knowledge banks\n# knowledge_banks \u003d project.list_knowledge_banks()\n\n# # Iterate over each Knowledge Bank and clear its contents\n# for kb in knowledge_banks:\n#     kb_handle \u003d project.get_knowledge_bank(kb[\u0027id\u0027])\n"
      ],
      "outputs": []
    }
  ]
}