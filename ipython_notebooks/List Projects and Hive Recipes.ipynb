{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.9.21",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "creator": "demo",
    "modifiedBy": "demo",
    "createdOn": 1756999673948,
    "customFields": {},
    "tags": []
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nimport pandas as pd\n\n# Connect to the DSS instance\nclient \u003d dataiku.api_client()\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Prepare a list to store results\nproject_hive_counts \u003d []\n\n# Iterate over all projects\nprojects \u003d client.list_project_keys()\nfor project_key in projects:\n    project \u003d client.get_project(project_key)\n    \n    # Get the list of recipes in the project\n    recipes \u003d project.list_recipes()\n    \n    # Count the number of Hive recipes\n    hive_count \u003d sum(1 for recipe in recipes if recipe[\u0027type\u0027] \u003d\u003d \u0027Hive\u0027)\n\n    # Append the result to the list\n    project_hive_counts.append({\u0027project_key\u0027: project_key, \u0027hive_recipe_count\u0027: hive_count})\n\n# Create a Pandas DataFrame with the results\ndf \u003d pd.DataFrame(project_hive_counts)\ndf.sort_values(by\u003d\"hive_recipe_count\", ascending\u003dFalse)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nimport pandas as pd\nfrom datetime import datetime\n\n# Connect to the DSS instance\nclient \u003d dataiku.api_client()\n\n# Prepare a list to store results\nproject_info \u003d []\n\n# Iterate over all projects\nprojects \u003d client.list_project_keys()\nfor project_key in projects:\n    try:\n        project \u003d client.get_project(project_key)\n        \n        # Get project metadata to extract owner information\n        project_metadata \u003d project.get_metadata()\n        project_summary \u003d project.get_summary()\n        last_modified_timestamp \u003d project_summary.get(\u0027versionTag\u0027, None).get(\u0027lastModifiedOn\u0027, None)\n        if last_modified_timestamp:\n            last_modified_date \u003d datetime.fromtimestamp(last_modified_timestamp / 1000).strftime(\u0027%Y-%m-%d-%H-%M-%S\u0027)\n        else:\n            last_modified_date \u003d \u0027unknown_date\u0027\n        \n        # Get the owner username\n        #owner_username \u003d project_metadata.get(\u0027owner\u0027, \u0027\u0027)\n        \n        # Get the list of recipes in the project\n        recipes \u003d project.list_recipes()\n        \n        # Count the number of Hive recipes\n        hive_recipes \u003d [recipe for recipe in recipes if recipe[\u0027type\u0027].lower() \u003d\u003d \u0027hive\u0027]\n        hive_count \u003d len(hive_recipes)\n        \n        \n        datasets \u003d project.list_datasets()\n        extracted_data \u003d [\n        {\n            \u0027type\u0027: row.get(\u0027type\u0027),\n            \u0027name\u0027: row.get(\u0027name\u0027),\n            \u0027connection\u0027: row.get(\u0027params\u0027, {}).get(\u0027connection\u0027),\n            \u0027table\u0027: row.get(\u0027params\u0027, {}).get(\u0027table\u0027),\n            \u0027catalog\u0027: row.get(\u0027params\u0027, {}).get(\u0027catalog\u0027),\n            \u0027schema\u0027: row.get(\u0027params\u0027, {}).get(\u0027schema\u0027),\n            # get the schema too\n        }\n        for row in datasets\n        ]\n        \n        for d in  project.list_datasets():\n            if d.get(\u0027type\u0027) \u003d\u003d \u0027hive\u0027\n        num_hive_datasets \u003d \n        \n        \n        # Append the result to the list\n        project_info.append({\n            \u0027PROJECT_KEY\u0027: project_key, \n            \u0027NUMBER_OF_HIVE_RECIPES_USED_IN_THIS_PROJECT\u0027: hive_count,\n            #\u0027PROJECT_OWNER_USERNAME\u0027: owner_username,\n            #\u0027PROJECT_OWNER_EMAIL\u0027: owner_email,\n            \u0027DATE_PROJECT_WAS_LAST_MODIFIED\u0027: last_modified_date,\n            # \u0027DATE_LAST_JOB_WAS_RUN\u0027: last_job_date\n        })\n    except Exception as e:\n        print(f\"Error processing project {project_key}: {str(e)}\")\n        # Add error entry to maintain record of all projects\n        project_info.append({\n            \u0027PROJECT_KEY\u0027: project_key,\n            \u0027NUMBER_OF_HIVE_RECIPES_USED_IN_THIS_PROJECT\u0027: -1,  # Error indicator\n            #\u0027PROJECT_OWNER_USERNAME\u0027: \"\",\n            #\u0027PROJECT_OWNER_EMAIL\u0027: \"\",\n            \u0027DATE_PROJECT_WAS_LAST_MODIFIED\u0027: \"unknown\",\n            # \u0027DATE_LAST_JOB_WAS_RUN\u0027: \"\",\n        })\n\n# Create a Pandas DataFrame with the results\ndf \u003d pd.DataFrame(project_info)\ndf\n# Display the DataFrame\n\n\n# Optional: If you want to export to CSV\n# df.to_csv(\u0027project_hive_recipe_analysis.csv\u0027, index\u003dFalse)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df"
      ],
      "outputs": []
    }
  ]
}