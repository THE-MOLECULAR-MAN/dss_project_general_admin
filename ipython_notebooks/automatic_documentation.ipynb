{
  "metadata": {
    "createdOn": 1761572597257,
    "creator": "admin",
    "customFields": {},
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "modifiedBy": "admin",
    "tags": []
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generate automatic documentation for datasets in a list of projects\n",
        "\n",
        "Written by Tim Honker - Oct 2025"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\n",
        "from dataikuapi.utils import DataikuException\n",
        "from dataiku import pandasutils as pdu\n",
        "import pandas as pd"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def get_dataset_long_description(dataset_handle):\n",
        "    dataset_metadata \u003d dataset_handle.get_metadata()\n",
        "    try:\n",
        "        return dataset_metadata[\u0027description\u0027]\n",
        "    except KeyError:\n",
        "        return \u0027\u0027\n",
        "\n",
        "\n",
        "def get_dataset_short_description(dataset_handle):\n",
        "    dataset_settings \u003d dataset_handle.get_settings().get_raw()\n",
        "    try:\n",
        "        return dataset_settings[\u0027shortDesc\u0027]\n",
        "    except KeyError:\n",
        "        return \u0027\u0027\n",
        "\n",
        "\n",
        "def get_dataset_column_descriptions(dataset_handle):\n",
        "    dataset_schema \u003d dataset_handle.get_schema()\n",
        "    try:\n",
        "        return [item[\"comment\"] for item in dataset_schema[\u0027columns\u0027]]\n",
        "    except KeyError:\n",
        "        return \u0027\u0027\n",
        "\n",
        "\n",
        "def dataset_has_full_documentation(project_handle, dataset_id):\n",
        "    \"\"\"x\"\"\"\n",
        "    # project_handle \u003d client.get_project(project_key)\n",
        "    dataset_handle \u003d project_handle.get_dataset(dataset_id)\n",
        "    \n",
        "    if not get_dataset_long_description(dataset_handle):\n",
        "        # print(f\u0027Dataset {dataset_id} lacks full documentation because empty: Long Description\u0027)\n",
        "        return False\n",
        "    \n",
        "    if not get_dataset_short_description(dataset_handle):\n",
        "        # print(f\u0027Dataset {dataset_id} lacks full documentation because empty: Short Description\u0027)\n",
        "        return False\n",
        "    \n",
        "    column_descriptions \u003d get_dataset_column_descriptions(dataset_handle)\n",
        "\n",
        "    if any(not s or not s.strip() for s in column_descriptions):\n",
        "        # print(f\u0027Dataset {dataset_id} lacks full documentation because empty: Column descriptions\u0027)\n",
        "        return False\n",
        "    \n",
        "    # print(f\u0027Dataset {dataset_id} has all description fields filled out.\u0027)\n",
        "    return True"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "client \u003d dataiku.api_client()\n",
        "\n",
        "for project_key in [\u0027TIM_HEALTH_DATA\u0027, \u0027HONKER_GENERAL_DSS_ADMIN\u0027, \u0027DATAIKU_DOCUMENTATION_RAG\u0027, \u0027PERSONAL_AGENTIC\u0027, \u0027TIM_PERSONAL_GDRIVE_RAG\u0027]:\n",
        "    # print(f\"Starting loop on project key: {project_key}\")\n",
        "    project_handle \u003d client.get_project(project_key)\n",
        "\n",
        "    for dataset in project_handle.list_datasets():\n",
        "        dataset_id \u003d dataset[\u0027name\u0027]\n",
        "        # print(f\"Starting loop on dataset id: {dataset_id}\")\n",
        "        \n",
        "        dataset_handle \u003d project_handle.get_dataset(dataset_id)\n",
        "    \n",
        "        if not dataset_has_full_documentation(project_handle, dataset_id):\n",
        "            print(f\"Auto-generating documentation for dataset: {dataset_id}\")\n",
        "            \n",
        "            try:\n",
        "                # this blocks execution, doesn\u0027t utilize Futures/JobID system\n",
        "                x \u003d dataset_handle.generate_ai_description(save_description\u003dTrue)\n",
        "            except DataikuException:\n",
        "                print(f\"[ERROR] Failed to update dataset {dataset_id} in {project_key}\")\n",
        "\n",
        "print(\"Successfully finished.\")"
      ],
      "outputs": []
    }
  ]
}