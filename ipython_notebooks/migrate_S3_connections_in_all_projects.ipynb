{
  "metadata": {
    "createdOn": 1746451947361,
    "creator": "tim.honker@dataiku.com",
    "customFields": {},
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "modifiedBy": "tim.honker@dataiku.com",
    "tags": [],
    "versionNumber": 1,
    "dkuGit": {
      "lastInteraction": 1756906584283,
      "gitReference": {
        "remote": "git@github.com:THE-MOLECULAR-MAN/dss_private.git",
        "checkout": "main",
        "remotePath": "admin/migrate_S3_connections_in_all_projects.ipynb",
        "remoteLogin": "",
        "lastHash": "bff3dd4953aa25023588eefba71b9b9f6a8dfc45",
        "lastTimestamp": 1755800954000,
        "isDirty": false
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Migrates all datasets that are S3 and not \"dataiku-managed-storage\" to \"dataiku-managed-storage\".\n",
        "\n",
        "import dataiku\n",
        "from dataiku import pandasutils as pdu\n",
        "import pandas as pd"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "new_s3_connection \u003d \"dataiku-managed-storage\""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "client \u003d dataiku.api_client()\n",
        "project_keys \u003d client.list_project_keys()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def get_all_dataset_metadata_for_project(project_handle):\n",
        "    ds \u003d project.list_datasets()\n",
        "    if len(ds) \u003d\u003d 0:\n",
        "        return pd.DataFrame()\n",
        "    else:\n",
        "        extracted_data \u003d [\n",
        "            {\n",
        "                \u0027type\u0027: row.get(\u0027type\u0027),\n",
        "                \u0027connection\u0027: row.get(\u0027params\u0027, {}).get(\u0027connection\u0027),\n",
        "                \u0027name\u0027: row.get(\u0027name\u0027),\n",
        "                \u0027table\u0027: row.get(\u0027params\u0027, {}).get(\u0027table\u0027),\n",
        "                \u0027catalog\u0027: row.get(\u0027params\u0027, {}).get(\u0027catalog\u0027),\n",
        "                \u0027schema\u0027: row.get(\u0027params\u0027, {}).get(\u0027schema\u0027),\n",
        "                \u0027path\u0027:  row.get(\u0027params\u0027, {}).get(\u0027path\u0027),\n",
        "            }\n",
        "            for row in ds\n",
        "        ]\n",
        "        return pd.DataFrame(extracted_data).sort_values(by\u003d[\u0027type\u0027, \u0027connection\u0027, \u0027name\u0027])\n",
        "\n",
        "    \n",
        "def check_connection_exists(connection_name):\n",
        "    return connection_name in dataiku.api_client().list_connections()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if check_connection_exists(\u0027dataiku-managed-storage\u0027):\n",
        "    for project_key in project_keys:\n",
        "        project \u003d client.get_project(project_key)\n",
        "        df \u003d get_all_dataset_metadata_for_project(project)\n",
        "\n",
        "        if df.empty:\n",
        "            print(f\u0027Project {project_key} has no datasets\u0027)\n",
        "            continue\n",
        "        unmigrated_S3_connections \u003d df[(df[\u0027type\u0027] \u003d\u003d \u0027S3\u0027) \u0026 (df[\u0027connection\u0027] !\u003d \u0027dataiku-managed-storage\u0027)]\n",
        "        dataset_names_to_migrate \u003d unmigrated_S3_connections[\u0027name\u0027].unique().tolist()\n",
        "        if len(dataset_names_to_migrate) \u003d\u003d 0:\n",
        "            print(f\"Project {project_key} has datasets, but none that need to be migrated\")\n",
        "        else:\n",
        "            for dataset_name in dataset_names_to_migrate:\n",
        "                dataset \u003d project.get_dataset(dataset_name)\n",
        "                settings \u003d dataset.get_settings()\n",
        "                # Update to the new S3 connection\n",
        "                settings.set_connection_and_path(new_s3_connection, settings.get_raw_params()[\u0027path\u0027])\n",
        "                settings.save()\n",
        "                print(f\"Project {project_key} dataset {dataset_name} updated to use connection: {new_s3_connection}\")\n",
        "else:\n",
        "    print(f\u0027This instance is on-prem, not cloud and does not have access to dataiku-managed-storage\u0027)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for project_key in project_keys:\n",
        "    project \u003d client.get_project(project_key)\n",
        "    df \u003d get_all_dataset_metadata_for_project(project)\n",
        "    print(df)"
      ],
      "outputs": []
    }
  ]
}