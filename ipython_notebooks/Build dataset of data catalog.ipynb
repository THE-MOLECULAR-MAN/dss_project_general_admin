{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.9.21",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "customFields": {},
    "creator": "demo",
    "tags": [],
    "createdOn": 1759339284072,
    "modifiedBy": "demo"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nfrom dataiku import pandasutils as pdu\nimport pandas as pd"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Connect to the Dataiku instance\nclient \u003d dataiku.api_client()\nproject \u003d client.get_project(\u0027SALES_FORECASTING_EXPORT\u0027)\n\n# List all datasets in the project\ndatasets \u003d project.list_datasets()\ndatasets"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "metadata_records \u003d []\n\n# Retrieve metadata for each dataset\nfor dataset_name in datasets:\n    dataset \u003d project.get_dataset(dataset_name)\n    # print(dataset)\n    if not dataset.exists():\n        # name \u003d dataset.name.get(\u0027name\u0027, \u0027Unknown\u0027)\n# .get_info()\n#         print(name)\n        metadata \u003d dataset.get_metadata()\n    #     # .get_raw_params()\n        # Extract relevant fields (for illustration purposes)\n        metadata_records.append({\n            \"name\": metadata[\"label\"],\n            \"description\": metadata.get(\"description\", \"\"),\n            \"tags\": metadata.get(\"tags\", [])\n        })\n\n\n        \n    else:\n        print(f\"Skipping dataset {dataset} since it does not exist\")\n        continue\n    \n\n\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n# Create a Pandas DataFrame\nmetadata_df \u003d pd.DataFrame(metadata_records)\n\n# Create a new dataset in DSS\nnew_dataset \u003d project.create_dataset(\"datasets_metadata\", {\"type\": \"INLINE\"})\nnew_dataset.write_with_schema(metadata_df)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nimport pandas as pd\n\n# Connect to the Dataiku instance\nclient \u003d dataiku.api_client()\nproject \u003d client.get_project(\"SALES_FORECASTING_EXPORT\")\n\n# List all datasets in the project\ndatasets \u003d project.list_datasets()\n\nmetadata_records \u003d []\n\n# Retrieve metadata for each dataset\nfor dataset_name in datasets:\n    dataset \u003d project.get_dataset(dataset_name)\n    metadata \u003d dataset.get_metadata()\n    # Extract relevant fields (for illustration purposes)\n    metadata_records.append({\n        \"name\": metadata[\"label\"],\n        \"description\": metadata.get(\"description\", \"\"),\n        \"tags\": metadata.get(\"tags\", [])\n    })\n\n# Create a Pandas DataFrame\nmetadata_df \u003d pd.DataFrame(metadata_records)\n\n# Create a new dataset in DSS\nnew_dataset \u003d project.create_dataset(\"datasets_metadata\", {\"type\": \"INLINE\"})\nnew_dataset.write_with_schema(metadata_df)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    }
  ]
}