{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.9.21",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "creator": "demo",
    "modifiedBy": "demo",
    "createdOn": 1758117375005,
    "tags": [
      "deleted-recipe-editor"
    ],
    "customFields": {}
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# update_all_dss_projects_on_github.py\n# Tim H 2025\n#\n# This script iterates through all projects on a DSS instance and attempts to push all commits to GitHub\n# for projects that are connected to GitHub.\n# It is intended to be run as a scenario on a schedule\n#\n# https://developer.dataiku.com/latest/tutorials/devtools/using-api-with-git-project/index.html\n# https://developer.dataiku.com/latest/api-reference/python/projects.html#dataikuapi.dss.project.DSSProjectGit.get_remote\n\nimport dataiku\nfrom dataiku import pandasutils as pdu\nimport pandas as pd"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "client \u003d dataiku.api_client()\nprojects \u003d client.list_projects()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "successful \u003d set()\nnot_connected \u003d set()\nerrored \u003d set()\n\nprojects_analysis \u003d []\n\nfor iter_project_key in client.list_project_keys():\n    try:\n        proj \u003d client.get_project(iter_project_key)\n        project_git \u003d proj.get_project_git()\n        r \u003d project_git.get_remote()\n        status \u003d project_git.get_status()\n                \n        has_github_repo \u003d len(status.get(\u0027remotes\u0027,[])) \u003e 0\n        projects_analysis.append({\"key\":iter_project_key, \"has_github_repo\": has_github_repo, \"status\": str(status), \"remote\": r})\n\n        if has_github_repo:\n            res_push \u003d project_git.push()\n            res_pull \u003d project_git.pull() # code studiodoes onot exist for PMM\n            \n            if (not res_push.get(\u0027success\u0027,False)) or (not res_pull.get(\u0027success\u0027,False)):\n#             if not res_push.get(\u0027success\u0027,False):\n                print(f\"[ERROR] pushing or pulling {iter_project_key}\")\n                errored.add(iter_project_key)\n                continue\n            successful.add(iter_project_key)\n        else:\n            # print(f\"{iter_project_key} is not connected to GitHub\")\n            not_connected.add(iter_project_key)\n    except Exception as e:\n        print(f\"[EXCEPTION] {iter_project_key}: {e}\")\n        errored.add(iter_project_key)\n        continue\n        \npd.DataFrame(projects_analysis).sort_values(by\u003d[\"has_github_repo\", \"remote\"])"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "successful"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "not_connected"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "errored"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    }
  ]
}